{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "H1: Similar Documents.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPjSsUYO-B1C"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uE0buyQiloe"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import collections\n",
        "import itertools\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfzCFDs796zV"
      },
      "source": [
        "# innstall java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# install spark (change the version number if needed)\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "\n",
        "# unzip the spark file to the current folder\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
        "\n",
        "# set your spark folder to your system path environment. \n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "# install findspark using pip\n",
        "!pip install -q findspark"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVVGU6_D-1A6"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEfyLaim9FX0"
      },
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGsSGm_M9pIi"
      },
      "source": [
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"MyApp\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oouaBhUa9Ugy"
      },
      "source": [
        "## Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzvbDrfOivcH"
      },
      "source": [
        "class Shingling:\n",
        "  \"\"\"A class Shingling that constructs k–shingles of a given length k (e.g., 10) from a given document, \n",
        "  computes a hash value for each unique shingle, \n",
        "  and represents the document in the form of an ordered set of its hashed k-shingles.\"\"\"\n",
        "  \n",
        "  def __init__(self, doc):\n",
        "    self.c = 2**32-1 #Mersenne prime\n",
        "    self.a = 7\n",
        "    self.b = 10\n",
        "    self.k = 5\n",
        "    self.shingles = set([doc[i:i+self.k] for i in range(len(doc))])\n",
        "    self.hashed_shingles = set([self.hashing(i) for i in self.shingles])\n",
        "  \n",
        "  def hashing(self, x):\n",
        "    x = int.from_bytes(x.encode(), \"little\")\n",
        "    return (self.a * x + self.b) % self.c\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dds2r7yApu7C"
      },
      "source": [
        "class CompareSets:\n",
        "  \"\"\"A class CompareSets that computes the Jaccard similarity of two sets of integers \n",
        "  – two sets of hashed shingles.\"\"\"\n",
        "  \n",
        "  def __init__(self, set_x, set_y):\n",
        "    intersection = len(list(set_x.intersection(set_y)))\n",
        "    union = (len(set_x) + len(set_y)) - intersection\n",
        "    self.jsim =  float(intersection) / union\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug-dSFcPpwnD"
      },
      "source": [
        "class MinHashing:\n",
        "  \"\"\"A class MinHashing that builds a minHash signature (in the form of a vector or a set)\n",
        "   of a given length n from a given set of integers (a set of hashed shingles).\"\"\"\n",
        "  def __init__(self, sets):\n",
        "\n",
        "    \n",
        "    self.c = 2**32-1 #Mersenne prime\n",
        "    self.k = 100\n",
        "    hash_list = [self.hashing for i in range(self.k)]\n",
        "    \n",
        "    #Unionize all the available shingles from the documents\n",
        "    \n",
        "    self.union_set = list(set().union(*sets))\n",
        "\n",
        "    I = np.zeros((len(self.union_set), len(sets)))\n",
        "    self.S = np.ones((self.k, len(sets))) * float(\"Inf\")\n",
        "\n",
        "    #Making the Input Matrix\n",
        "    for c in range(len(sets)):\n",
        "      for r in range(len(self.union_set)):\n",
        "        if self.union_set[r] in sets[c]:\n",
        "          I[r,c] = 1\n",
        "\n",
        "\n",
        "    #Making the Signature Matrix\n",
        "\n",
        "    for r in range(I.shape[0]):\n",
        "      computed_hash = list()\n",
        "      for hash_func in hash_list:\n",
        "        computed_hash.append(hash_func(r))\n",
        "      for c in range(I.shape[1]):\n",
        "        if I[r,c] == 1:\n",
        "          for k in range(len(computed_hash)):\n",
        "            if computed_hash[k] < self.S[k,c]:\n",
        "              self.S[k,c] = computed_hash[k]\n",
        "\n",
        "\n",
        "\n",
        "  def hashing(self, x):\n",
        "    a = random.randint(1,1000)\n",
        "    b = random.randint(1,1000)\n",
        "\n",
        "    return (a * x + b) % self.c\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86V3DABwpzUy"
      },
      "source": [
        "class CompareSignatures:\n",
        "  \"\"\"A class CompareSignatures that estimates similarity of two integer vectors –\n",
        "   minhash signatures – as a fraction of components, in which they agree.\"\"\"\n",
        "  def __init__(self, vec1, vec2):\n",
        "    match = 0\n",
        "    for i in range(len(vec1)):\n",
        "      if vec1[i] == vec2[i]:\n",
        "        match += 1\n",
        "    self.sim = match / len(vec1)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKX9WpM3p2Jv"
      },
      "source": [
        "class LSH:\n",
        "  \"\"\" A class LSH that implements the LSH technique: \n",
        "  given a collection of minhash signatures (integer vectors) and a similarity threshold t, \n",
        "  the LSH class (using banding and hashing) finds candidate pairs of signatures agreeing \n",
        "  on at least fraction t of their components.\"\"\"\n",
        "  def __init__(self, S, t, b=20):\n",
        "    #Initialize band size...\n",
        "    n , d = S.shape\n",
        "    r = n/b\n",
        "    t_th = (1/b)**(1/r)\n",
        "    assert( n % b == 0)\n",
        "    self.k_buckets = 2**32\n",
        "\n",
        "    bands = np.array_split(S, b, axis=0)\n",
        "    buckets = collections.defaultdict(list)\n",
        "    # Iterating through bands and hash to buckets\n",
        "    for i in range(b):\n",
        "      for j in range(d):\n",
        "\n",
        "        hash_val = self.hash_func(bands[i][:,j])\n",
        "        buckets[str(hash_val) + \",\" + str(i)].append(j)\n",
        "\n",
        "\n",
        "    matches = collections.defaultdict(int)\n",
        "    self.c_pairs = list()\n",
        "    \n",
        "    # Find candidate pairs\n",
        "   \n",
        "    for key, bucket in buckets.items():\n",
        "      if len(bucket)> 1:\n",
        "        for idx in bucket:\n",
        "          for jdx in bucket:\n",
        "            if idx != jdx:\n",
        "\n",
        "              matches[tuple(sorted((idx, jdx)))] += 1\n",
        "\n",
        "    for key, value in matches.items():\n",
        "      if value/b >=t:\n",
        "        if key not in self.c_pairs:\n",
        "          self.c_pairs.append(key)\n",
        "  def hash_func(self, v):\n",
        "    \n",
        "    nr = hash(tuple(list(v)))\n",
        "    return nr % self.k_buckets\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDPJEjjzxGjS"
      },
      "source": [
        "To test and evaluate scalability (the execution time versus the size of input dataset) of your implementation, write a program that uses your classes to find similar documents in a corpus of 5-10 documents. Choose a similarity threshold s (e.g., 0,8) that states that two documents are similar if the Jaccard similarity of their shingle sets is at least s. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6omgO80f9H9T"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZdqQPpup45y"
      },
      "source": [
        "def opendoc(name):\n",
        "  with open(name) as f:\n",
        "      doc = f.read()\n",
        "  return doc"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uao5qHhM7wDB"
      },
      "source": [
        "ds = []\n",
        "ogs = []\n",
        "df = pd.read_csv(\"content.csv\")\n",
        "for _,c in df.head(100)[\"content\"].iteritems():\n",
        "  ogs.append(c)\n",
        "  ds.append(Shingling(c))\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U40LBtPBzdf-"
      },
      "source": [
        "## Compare Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj5Q4QV9SI-P"
      },
      "source": [
        "docs = list()\n",
        "og_docs = list()\n",
        "idxs = set()\n",
        "for i in range(len(ds)):\n",
        "  for j in range(len(ds)):\n",
        "    similar = CompareSets(ds[i].hashed_shingles, ds[j].hashed_shingles).jsim\n",
        "    if 0.4 < similar and i != j:\n",
        "      if i not in idxs: \n",
        "        docs.append(ds[i])\n",
        "        og_docs.append(ogs[i])\n",
        "      if j not in idxs:\n",
        "        docs.append(ds[j])\n",
        "        og_docs.append(ogs[j])\n",
        "      idxs.add(i)\n",
        "      idxs.add(j)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s4AYNeBHKQa",
        "outputId": "68e72d8d-58c0-4d17-fd0f-c1412ec1af7b"
      },
      "source": [
        "CompareSets(docs[0].hashed_shingles, docs[1].hashed_shingles).jsim"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5400192864030858"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YioKqkbxzhvB"
      },
      "source": [
        "## Compare Signatures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97Ayvzduz2bq"
      },
      "source": [
        "sets = list()\n",
        "for d in docs:\n",
        "  sets.append(d.hashed_shingles)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4t9QVlMYEpc",
        "outputId": "f33715dc-fbe7-4ecd-e912-02c25a2d80f8"
      },
      "source": [
        "print(len(sets))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEH_B5yHnl2Y"
      },
      "source": [
        "sig_M = MinHashing(sets).S"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpAEgfJWSvpY",
        "outputId": "992d1f0e-f083-42c2-d93a-2d48a0460c0a"
      },
      "source": [
        "CompareSignatures(sig_M[:,0], sig_M[:,1]).sim"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.65"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtZNjowIRRf_"
      },
      "source": [
        "## Find candidate Pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO__gVSqFZeS",
        "outputId": "14339c22-5317-4002-a5e3-31cacf9ca33e"
      },
      "source": [
        "for a, b in LSH(sig_M, 0.8).c_pairs:\n",
        "  jacc_sim = CompareSets(docs[a].shingles, docs[b].shingles).jsim\n",
        "  pairs[(a,b)] = jacc_sim\n",
        "  if jacc_sim < 0.8:\n",
        "    print(\"False Positive\")\n",
        "  print(\"Documents:\", a,b)\n",
        "  print(\"Jaccard Similarity:\", jacc_sim)\n",
        "  print(\"------\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents: 9 10\n",
            "Jaccard Similarity: 0.8316326530612245\n",
            "------\n",
            "Documents: 9 11\n",
            "Jaccard Similarity: 0.8994413407821229\n",
            "------\n",
            "Documents: 10 11\n",
            "Jaccard Similarity: 0.8214285714285714\n",
            "------\n",
            "False Positive\n",
            "Documents: 14 15\n",
            "Jaccard Similarity: 0.7439483593329748\n",
            "------\n",
            "Documents: 16 18\n",
            "Jaccard Similarity: 0.8384321223709369\n",
            "------\n",
            "Documents: 19 20\n",
            "Jaccard Similarity: 0.8886966551326413\n",
            "------\n",
            "Documents: 27 28\n",
            "Jaccard Similarity: 0.8395522388059702\n",
            "------\n",
            "Documents: 29 30\n",
            "Jaccard Similarity: 0.8568453930244664\n",
            "------\n",
            "False Positive\n",
            "Documents: 3 4\n",
            "Jaccard Similarity: 0.7941888619854721\n",
            "------\n",
            "Documents: 16 17\n",
            "Jaccard Similarity: 0.8255144032921811\n",
            "------\n",
            "False Positive\n",
            "Documents: 17 18\n",
            "Jaccard Similarity: 0.7482935153583617\n",
            "------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaqZZwbpRjBF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}